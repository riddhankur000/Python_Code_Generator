{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvgyWqOwcKzQ"
      },
      "outputs": [],
      "source": [
        "!pip install \"sagemaker>=2.175.0\" --upgrade --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sagemaker\n",
        "import boto3\n",
        "sess=sagemaker.Session()\n",
        "# sagemaker session bucket -> used dor uploading data, models and logs\n",
        "# sagemaker will automatically create this bucket if it not exists\n",
        "sagemaker_session_bucket=None\n",
        "if sagemaker_session_bucket is None and sess is not None:\n",
        "    # set to default bucket if a bucket name is not given\n",
        "    sagemaker_session_bucket=sess.default_bucket()\n",
        "\n",
        "\n",
        "try:\n",
        "    role=sagemaker.get_execution_role()\n",
        "except ValueError:\n",
        "    iam=boto3.client('iam')\n",
        "    role=iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
        "\n",
        "sess=sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
        "\n",
        "print(f\"sagemaker role arn: {role}\")\n",
        "print(f\"sagemaker session region: {sess.boto_region_name}\")"
      ],
      "metadata": {
        "id": "TekLkImCgBwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
        "\n",
        "# retrieve the llm image uri\n",
        "llm_image = get_huggingface_llm_image_uri(\n",
        "  \"huggingface\",\n",
        "  version=\"0.8.2\"\n",
        ")\n",
        "\n",
        "# print ecr image uri\n",
        "print(f\"llm image uri: {llm_image}\")"
      ],
      "metadata": {
        "id": "ElIiDda_eCCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from sagemaker.huggingface import HuggingFaceModel\n",
        "\n",
        "# sagemaker config\n",
        "instance_type = \"ml.g5.2xlarge\n",
        "number_of_gpu = 1\n",
        "health_check_timeout = 200\n",
        "\n",
        "# Define Model and Endpoint configuration parameter\n",
        "config = {\n",
        "  'HF_MODEL_ID': \"Model_Repository_id_in_Huggingface\", # model id from huggingface.co/models\n",
        "  'SM_NUM_GPUS': json.dumps(number_of_gpu), # Number of GPU used per replica\n",
        "  'MAX_INPUT_LENGTH': json.dumps(2048),  # Max length of input text\n",
        "  'MAX_TOTAL_TOKENS': json.dumps(4096),  # Max length of the generation (including input text)\n",
        "  'MAX_BATCH_TOTAL_TOKENS': json.dumps(8192),  # Limits the number of tokens that can be processed in parallel during the generation\n",
        "  'HUGGING_FACE_HUB_TOKEM': json.dumps(\"Hugging_face_token\"), # Hugging Face Token\n",
        "  # 'HF_MODEL_QUANTIZE': \"bitsandbytes\", # Quantization Config\n",
        "}\n",
        "\n",
        "# check if token is set\n",
        "assert config['HUGGING_FACE_HUB_TOKEN'] != \"Hugging_face_token\", f\"Please set the HUGGING_FACE_HUB_TOKEN in the config and run the cell again\"\n",
        "\n",
        "# create HuggingFaceModel with the image uri\n",
        "llm_model = HuggingFaceModel(\n",
        "  role=role,\n",
        "  image_uri=llm_image,\n",
        "  env=config\n",
        ")"
      ],
      "metadata": {
        "id": "fpvfBvHneWhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm=llm_model.deploy(\n",
        "    initial_instance_count=1,\n",
        "    instance_type=instance_type,\n",
        "    container_startup_health_check_timeout=health_check_timeout, # 10 minutes to be able to load the model\n",
        ")"
      ],
      "metadata": {
        "id": "QIlj-OlpfbO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input Format :: <s>[INST] {human_text} [/INST] {assistant_text} {code_text}</s>"
      ],
      "metadata": {
        "id": "Zv1C4FEnNBEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_llama2_prompt(messages):\n",
        "  start_prompt = '<s>[INST] '\n",
        "  end_prompt = ' [/INST]'\n",
        "  conversation=[]\n",
        "  for index,message in enumerate(messages):\n",
        "    if message[\"role\"]==\"system\" and index==0:\n",
        "      conversation.append(f\"<<SYS>>\\n{message['content']}\\n<</SYS>>\\n\")\n",
        "    elif message[\"role\"]==\"user\":\n",
        "      conversation.append(f\"{message['content']}\")\n",
        "    else:\n",
        "      conversation.append(f\"{message['content']}</s>\")\n",
        "  prompt=start_prompt+\"\".join(conversation)+end_prompt\n",
        "  return prompt\n"
      ],
      "metadata": {
        "id": "6NqL1qLC0EoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[{\"role\":\"system\",\"content\":\"Write a Pyhton code for Binary Search Algorithm\"}]\n",
        "instruction=\"Consider the array [2,6,8,1,3,9] and find the number8\"\n",
        "messages.append({\"role\":\"user\",\"content\":instruction})\n",
        "prompt=build_llama2_prompt(messages)\n",
        "print(prompt)\n"
      ],
      "metadata": {
        "id": "Irg4G7mhNWWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer=llm.predict({\"inputs\":prompt})\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "4aBA8OeffVMJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}